{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c511b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f298f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1       2       3       4       5       6       7       8       9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       10  ...      52      53      54      55      56      57      58  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       59      60  label  \n",
       "0  0.0090  0.0032      R  \n",
       "1  0.0052  0.0044      R  \n",
       "2  0.0095  0.0078      R  \n",
       "3  0.0040  0.0117      R  \n",
       "4  0.0107  0.0094      R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [i for i in range(1,61)]\n",
    "columns.append(\"label\")\n",
    "df = pd.read_csv(\"sonar.all-data\",delimiter = \",\",names = columns,header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ba29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].replace({'R': 0, 'M': 1},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16488d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[columns[:-1]], df[columns[-1]], test_size=0.33, random_state=42)\n",
    "#to avoid class invalance we use train_test_split() fun as in data set first it has R data then M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c437b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e3408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 139)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.T\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803d4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a10509",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfTrainSamples = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd5eaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.expand_dims(y_train,axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1b2eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12239492]\n",
      " [0.71665882]\n",
      " [0.69973927]\n",
      " [0.63597091]\n",
      " [0.89572801]\n",
      " [0.4631575 ]\n",
      " [0.7920902 ]\n",
      " [0.7289766 ]\n",
      " [0.10245105]\n",
      " [0.84011024]\n",
      " [0.23141983]\n",
      " [0.39053157]\n",
      " [0.65661502]\n",
      " [0.38265444]\n",
      " [0.23141772]\n",
      " [0.51421101]\n",
      " [0.17466414]\n",
      " [0.0151254 ]\n",
      " [0.6436466 ]\n",
      " [0.99445401]\n",
      " [0.71448558]\n",
      " [0.92373192]\n",
      " [0.38149428]\n",
      " [0.58964427]\n",
      " [0.56622324]\n",
      " [0.89967764]\n",
      " [0.65864689]\n",
      " [0.27232068]\n",
      " [0.66800005]\n",
      " [0.39342514]\n",
      " [0.01368744]\n",
      " [0.50651244]\n",
      " [0.11537053]\n",
      " [0.61285816]\n",
      " [0.25467831]\n",
      " [0.15597901]\n",
      " [0.11467881]\n",
      " [0.15805777]\n",
      " [0.08179474]\n",
      " [0.71499296]\n",
      " [0.97210872]\n",
      " [0.91030939]\n",
      " [0.9809626 ]\n",
      " [0.25405126]\n",
      " [0.62795697]\n",
      " [0.48871739]\n",
      " [0.51901091]\n",
      " [0.11182087]\n",
      " [0.35187945]\n",
      " [0.81753768]\n",
      " [0.57492062]\n",
      " [0.29478657]\n",
      " [0.63172078]\n",
      " [0.59000728]\n",
      " [0.01306581]\n",
      " [0.52515481]\n",
      " [0.28258426]\n",
      " [0.38678846]\n",
      " [0.55294239]\n",
      " [0.78344152]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "W = np.random.rand(60,1)\n",
    "print(W)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24495acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843992590294364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.rand()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b89c76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "alpha = 0.001\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    \n",
    "#     print(type(A))\n",
    "    \n",
    "    # Loss Function\n",
    "    J = log_loss(y_train,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_train\n",
    "    dw = np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2651d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c21f96df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79651058])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d57828",
   "metadata": {},
   "source": [
    "# Testing Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61081fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights for x's\n",
    "\n",
    "W1=np.array([[ 0.96266859],\n",
    "       [ 0.29039567],\n",
    "       [ 0.3000177 ],\n",
    "       [ 1.76436787],\n",
    "       [ 1.42070033],\n",
    "       [ 0.13522691],\n",
    "       [-1.1033552 ],\n",
    "       [-0.77395302],\n",
    "       [ 1.22429753],\n",
    "       [ 0.2041659 ],\n",
    "       [ 2.51195143],\n",
    "       [ 1.58184071],\n",
    "       [-0.32521909],\n",
    "       [-0.81368099],\n",
    "       [-0.59636208],\n",
    "       [-0.68299006],\n",
    "       [ 0.39249264],\n",
    "       [-0.03698274],\n",
    "       [ 0.27440402],\n",
    "       [ 0.03999919],\n",
    "       [ 0.15161937],\n",
    "       [ 0.12763717],\n",
    "       [ 0.31203859],\n",
    "       [ 1.08001276],\n",
    "       [-0.38278762],\n",
    "       [-0.46783195],\n",
    "       [-0.11373291],\n",
    "       [ 0.09548073],\n",
    "       [ 0.19947519],\n",
    "       [ 1.01445942],\n",
    "       [-2.49386605],\n",
    "       [ 0.7140659 ],\n",
    "       [ 1.02471573],\n",
    "       [-0.38867878],\n",
    "       [-0.32994211],\n",
    "       [-0.78379918],\n",
    "       [-1.12088961],\n",
    "       [ 0.05651628],\n",
    "       [ 0.6306721 ],\n",
    "       [-1.70432379],\n",
    "       [-0.30652134],\n",
    "       [ 0.32698444],\n",
    "       [ 1.57722672],\n",
    "       [ 0.6790418 ],\n",
    "       [ 1.5883846 ],\n",
    "       [ 1.38764186],\n",
    "       [ 0.43359497],\n",
    "       [ 1.81824148],\n",
    "       [ 0.85203445],\n",
    "       [-0.0271304 ],\n",
    "       [ 0.80561697],\n",
    "       [ 1.00264405],\n",
    "       [ 0.46323458],\n",
    "       [ 1.07160694],\n",
    "       [ 0.02546764],\n",
    "       [ 0.13167488],\n",
    "       [ 0.0733669 ],\n",
    "       [ 0.74305845],\n",
    "       [ 0.43982924],\n",
    "       [ 0.23269647]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c06cf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7476542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight for biased\n",
    "b1=np.array([-1.553573])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3dbbaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.553573])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fedadc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 69)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.T\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bccd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.expand_dims(y_test,axis =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00116ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfTrainSamples = X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecc0daf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 479.389463884521\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W1.T,X_test,) + b1\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "    \n",
    "    predictions=A.T\n",
    "    # Loss Function\n",
    "    J = log_loss(y_test,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_test\n",
    "    dw = np.dot(X_test,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "638d33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "134b476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e76de90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e57d99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f52da86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681159420289855"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions,y_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f2b5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5529bb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  6],\n",
       "       [10, 28]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.T,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed4cb3",
   "metadata": {},
   "source": [
    "# Trying different values for alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d3d7a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.002\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    \n",
    "#     print(type(A))\n",
    "    \n",
    "    # Loss Function\n",
    "    J = log_loss(y_train,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_train\n",
    "    dw = np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d6fdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 360.21659711854045\n",
      "Error: 359.68951901647597\n",
      "Error: 381.55086034567523\n",
      "Error: 1140.1062645018726\n",
      "Error: 1007.8733236935329\n",
      "Error: 1138.0204083134565\n",
      "Error: 975.2064447333958\n",
      "Error: 1139.0707861474596\n",
      "Error: 1074.0498324919397\n",
      "Error: 974.2764958516434\n",
      "Error: 1106.5884837711178\n",
      "Error: 1006.9190617391157\n",
      "Error: 1004.9722797021182\n",
      "Error: 1038.517843496957\n",
      "Error: 972.380285344205\n",
      "Error: 1039.5110560970288\n",
      "Error: 1005.9521601863645\n",
      "Error: 1039.5110560970288\n",
      "Error: 1040.4909365812753\n",
      "Error: 1107.5953962867784\n",
      "Error: 939.7377194567326\n",
      "Error: 1170.4119710883078\n",
      "Error: 738.7788584627214\n",
      "Error: 1233.8277727708805\n",
      "Error: 705.0938929705236\n",
      "Error: 1233.8277727708805\n",
      "Error: 705.0938929705236\n",
      "Error: 1233.8277727708805\n",
      "Error: 705.0938929705236\n",
      "Error: 1200.45702129426\n",
      "Error: 705.0938929705237\n",
      "Error: 1230.207196067706\n",
      "Error: 637.6945750111054\n",
      "Error: 1132.5290985631127\n",
      "Error: 738.7788584627214\n",
      "Error: 1162.3565629149807\n",
      "Error: 671.3990566108914\n",
      "Error: 1132.5290985631127\n",
      "Error: 771.5794575029904\n",
      "Error: 1132.5290985631127\n",
      "Error: 738.7788584627214\n",
      "Error: 1129.0244255625084\n",
      "Error: 705.0938929705237\n",
      "Error: 1130.2114435861483\n",
      "Error: 705.0938929705237\n",
      "Error: 1162.3565629149807\n",
      "Error: 705.0938929705237\n",
      "Error: 1063.4515457732914\n",
      "Error: 805.2333745790402\n",
      "Error: 997.7180891137543\n",
      "Error: 838.8764342147483\n",
      "Error: 996.6203240661428\n",
      "Error: 805.2333745790402\n",
      "Error: 1030.044574995506\n",
      "Error: 771.5794575029904\n",
      "Error: 1096.8406921095277\n",
      "Error: 671.3990566108915\n",
      "Error: 1194.4205260375666\n",
      "Error: 604.7963170933948\n",
      "Error: 1194.4205260375666\n",
      "Error: 638.5194425446425\n",
      "Error: 1194.4205260375666\n",
      "Error: 604.7963170933948\n",
      "Error: 1193.1509288195998\n",
      "Error: 604.7963170933948\n",
      "Error: 1193.1509288195998\n",
      "Error: 604.7963170933948\n",
      "Error: 1194.4205260375666\n",
      "Error: 603.9806661497317\n",
      "Error: 1194.4205260375666\n",
      "Error: 603.9806661497317\n",
      "Error: 1161.1296432778847\n",
      "Error: 603.9806661497317\n",
      "Error: 1193.1509288195998\n",
      "Error: 571.064178740105\n",
      "Error: 1226.3976360862546\n",
      "Error: 538.1124213696519\n",
      "Error: 1258.2815744566913\n",
      "Error: 537.3232244940441\n",
      "Error: 1226.3976360862546\n",
      "Error: 569.4418897548211\n",
      "Error: 1126.5908668829738\n",
      "Error: 602.3215038210701\n",
      "Error: 1129.0244255625084\n",
      "Error: 667.9631283182584\n",
      "Error: 996.6203240661429\n",
      "Error: 735.2601050300162\n",
      "Error: 996.6203240661429\n",
      "Error: 802.5125627588423\n",
      "Error: 964.2608139811589\n",
      "Error: 802.5125627588423\n",
      "Error: 1030.044574995506\n",
      "Error: 701.6170453943081\n",
      "Error: 1062.301915714617\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    \n",
    "#     print(type(A))\n",
    "    \n",
    "    # Loss Function\n",
    "    J = log_loss(y_train,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_train\n",
    "    dw = np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46197205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n",
      "Error: 634.2986138697581\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    \n",
    "#     print(type(A))\n",
    "    \n",
    "    # Loss Function\n",
    "    J = log_loss(y_train,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_train\n",
    "    dw = np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d6ecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 634.2986138697581\n",
      "Error: 768.8920374650323\n",
      "Error: 802.5125627588423\n",
      "Error: 802.5125627588423\n",
      "Error: 801.5826138770899\n",
      "Error: 799.6864033696518\n",
      "Error: 866.8171741224755\n",
      "Error: 866.8171741224755\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 866.8171741224755\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 866.8171741224755\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 900.3627379173142\n",
      "Error: 866.8171741224755\n",
      "Error: 933.8946017965644\n",
      "Error: 866.8171741224755\n",
      "Error: 899.3558254016536\n",
      "Error: 866.8171741224755\n",
      "Error: 900.3627379173142\n",
      "Error: 865.8239615224036\n",
      "Error: 866.8171741224755\n",
      "Error: 899.3558254016536\n",
      "Error: 833.2582782118111\n",
      "Error: 899.3558254016536\n",
      "Error: 865.8239615224036\n",
      "Error: 865.8239615224036\n",
      "Error: 832.2783977275649\n",
      "Error: 899.3558254016536\n",
      "Error: 832.2783977275649\n",
      "Error: 899.3558254016536\n",
      "Error: 833.2582782118111\n",
      "Error: 899.3558254016536\n",
      "Error: 865.8239615224036\n",
      "Error: 832.2783977275649\n",
      "Error: 899.3558254016536\n",
      "Error: 833.2582782118111\n",
      "Error: 899.3558254016536\n",
      "Error: 899.3558254016536\n",
      "Error: 799.6864033696518\n",
      "Error: 898.3348297374977\n",
      "Error: 833.2582782118111\n",
      "Error: 898.3348297374977\n",
      "Error: 833.2582782118111\n",
      "Error: 898.3348297374977\n",
      "Error: 799.6864033696518\n",
      "Error: 898.3348297374977\n",
      "Error: 866.8171741224755\n",
      "Error: 864.817049006743\n",
      "Error: 800.6406653240687\n",
      "Error: 898.3348297374977\n",
      "Error: 898.3348297374977\n",
      "Error: 800.6406653240687\n",
      "Error: 898.3348297374977\n",
      "Error: 865.8239615224036\n",
      "Error: 866.8171741224755\n",
      "Error: 864.817049006743\n",
      "Error: 799.6864033696518\n",
      "Error: 898.3348297374977\n",
      "Error: 865.8239615224036\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 800.6406653240687\n",
      "Error: 897.2993513830849\n",
      "Error: 865.8239615224036\n",
      "Error: 798.7195018169004\n",
      "Error: 863.796053342587\n",
      "Error: 800.6406653240687\n",
      "Error: 897.2993513830849\n",
      "Error: 865.8239615224036\n",
      "Error: 798.7195018169004\n",
      "Error: 863.796053342587\n",
      "Error: 798.7195018169004\n",
      "Error: 864.817049006743\n",
      "Error: 831.2851851274929\n",
      "Error: 798.7195018169004\n",
      "Error: 863.796053342587\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 800.6406653240687\n",
      "Error: 897.2993513830849\n",
      "Error: 831.2851851274929\n",
      "Error: 797.7396213326541\n",
      "Error: 864.817049006743\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 799.6864033696518\n",
      "Error: 897.2993513830849\n",
      "Error: 800.6406653240687\n",
      "Error: 897.2993513830849\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "for n in range(100):\n",
    "\n",
    "    # Net input function output\n",
    "    Z = np.dot(W.T,X_train,) + b\n",
    "\n",
    "    # Activation function \n",
    "    A = sigmoid(Z)\n",
    "\n",
    "    \n",
    "    # To change values to int\n",
    "    A = np.where(A < 0.5, 0, 1)\n",
    "\n",
    "    \n",
    "#     print(type(A))\n",
    "    \n",
    "    # Loss Function\n",
    "    J = log_loss(y_train,A)\n",
    "    print(\"Error:\",J)\n",
    "\n",
    "    dz = A - y_train\n",
    "    dw = np.dot(X_train,dz.T)/numOfTrainSamples\n",
    "    db = np.sum(dz,axis =1)/numOfTrainSamples\n",
    "    \n",
    "    \n",
    "    W = W - alpha * dw\n",
    "    b = b - alpha *db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0bb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102094f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d5f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
